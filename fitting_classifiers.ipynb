{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure script.\n",
    "\n",
    "We set global variables that define behaviour of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"   \n",
    "DATA = \"CAP\"\n",
    "CLASS_LABEL = 'pca_death_code'  # Target label to predict\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "CLASSIFIER = 'rf'\n",
    "LOAD_CLASSIFIER = True\n",
    "CLASSIFIER_FILENAME = 'cap_%s_gridsearch.joblib' % CLASSIFIER\n",
    "\n",
    "\n",
    "# Specify the hyperparameters to optimise when training classifiers:\n",
    "PARAMETERS = {\n",
    "    'vect__ngram_range': ((1, 2),),\n",
    "    'vect__max_df': (0.7,),\n",
    "    'vect__min_df': (5,),\n",
    "    'vect__max_features': (1500,),\n",
    "}\n",
    "\n",
    "if CLASSIFIER == \"rf\":    \n",
    "    PARAMETERS['clf__n_estimators'] = (100,500, 1000, 2000)\n",
    "    #PARAMETERS['clf__max_features'] = (0.1,0.2)\n",
    "    PARAMETERS['clf__max_depth'] = (5,10,15)\n",
    "    PARAMETERS['clf__max_samples'] = (0.7,0.8,0.9)\n",
    "    PARAMETERS['clf__min_samples_leaf'] = (2,3,4)\n",
    "    PARAMETERS['clf__n_estimators'] = (100,)\n",
    "    PARAMETERS['clf__max_samples'] = (0.8,)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "elif CLASSIFIER == 'lr':\n",
    "    PARAMETERS['clf__C'] = (0.001, 0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "    PARAMETERS['clf__penalty'] = ('l1', 'l2', 'elasticnet', 'none')\n",
    "    PARAMETERS['clf__fit_intercept'] = (True, False)\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "elif CLASSIFIER == 'svc':\n",
    "    PARAMETERS['clf__C'] = (0.001, 0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "    PARAMETERS['clf__kernel'] = ('linear', 'poly', 'sigmoid')\n",
    "    PARAMETERS['clf__probability'] = (True, )\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(random_state=RANDOM_STATE)\n",
    "    \n",
    "\n",
    "CV = 5\n",
    "SCORING = None # Specify scoring metric to use for GridsearchCV (or use default if None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "\n",
    "from cap_helper import *\n",
    "\n",
    "from helper import (pd_print, \n",
    "                    accuracy,\n",
    "                    lemmatize_text,\n",
    "                    summarise_gridsearch_classifier,\n",
    "                    calibrate_random_forest, \n",
    "                    plot_calibration_curve,\n",
    "                    plot_calibration_curve_easy_hard,\n",
    "                    plot_roc_curve,\n",
    "                    compute_all_metrics)\n",
    "\n",
    "from explainability import (get_rf_feature_importances,\n",
    "                            wordcloud,\n",
    "                            run_tree_interpreter,\n",
    "                            get_ti_feature_contributions_for_instance_i,\n",
    "                            get_ti_feature_contributions_average)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CAP prostate cancer data for preprocessing.\")\n",
    "df = load_data(DATA_DIR)\n",
    "# Combine text from all feature columns into a single string column\n",
    "df = concatenate_feature_columns(df)\n",
    "# Link to dates of death:\n",
    "df = add_dates(df, DATA_DIR)\n",
    "# Link to reviewer Ids:\n",
    "df = add_reviewer_ids(df, DATA_DIR)\n",
    "# Convert all dates to be in units of months before/after death (Note: this regex is not foolproof)\n",
    "df = convert_dates_relative(df)  \n",
    "\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reviews are dominated by three authors:\n",
    "pd_print(get_reviewer_counts(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having loaded and pre-processed the data we can start to train classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.combined, df[CLASS_LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = lemmatize_text(X, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y[y==1]))\n",
    "print(len(y[y==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(documents, \n",
    "                                                    df[CLASS_LABEL], \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CLASSIFIER:\n",
    "    clf = load('models/' + CLASSIFIER_FILENAME)\n",
    "    \n",
    "else:\n",
    "    clf = GridSearchCV(pipeline, PARAMETERS, n_jobs=-1, verbose=1, cv=CV, scoring=SCORING)\n",
    "    clf.fit(X_train, y_train)\n",
    "    dump(clf, 'models/' + CLASSIFIER_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarise_gridsearch_classifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dict = {'train': X_train, 'test': X_test}\n",
    "y_dict = {'train': y_train, 'test': y_test}\n",
    "clf_dict = {'train': clf, 'test': clf}\n",
    "names = ['train', 'test']\n",
    "\n",
    "plot_roc_curve(clf_dict, X_dict, y_dict, names, pos_label=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now attempt to calibration the random forest:\n",
    "\n",
    "Note: the main results presented in the publication are for the uncalibrated classifiers trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_clf = calibrate_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(clf, calibrated_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratify based on 'easy' and 'hard' cases:\n",
    "\n",
    "Note: In CAP this is determined by the cause of death assignment route, essentially the harder it is to determine the cause of death the more levels of review and deliberartion are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cap_helper import get_easy_and_hard_cases\n",
    "easy_x, hard_x, easy_y, hard_y = get_easy_and_hard_cases(df, subset_x=X_test, subset_y=y_test)\n",
    "plot_calibration_curve_easy_hard(calibrated_clf, easy_x, hard_x, easy_y, hard_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['easy cases (cod_route: 1,5)', 'hard cases (cod_route: 2,4)']\n",
    "clf_dict = {names[0]: clf, names[1]: clf}\n",
    "X_dict = {names[0]: easy_x, names[1]: hard_x}\n",
    "y_dict = {names[0]: easy_y, names[1]: hard_y}\n",
    "plot_roc_curve(clf_dict, X_dict, y_dict, names)\n",
    "plt.savefig('roc_easy_hard.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_x, hard_x, easy_y, hard_y = get_easy_and_hard_cases(df, subset_x=X, subset_y=y)\n",
    "print(\"There are %d easy cases.\" % len(easy_x))\n",
    "print(\"There are %d hard cases.\" % len(hard_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
