{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suspected-jamaica",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- remove unnecessary imports\n",
    "- add shap\n",
    "- compare FIMP rankings\n",
    "- remove 'temporary' stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-murray",
   "metadata": {},
   "source": [
    "## Interpretability outputs\n",
    "\n",
    "Here we compare a number of standard interpretability methods and use them to produce bespoke visualisations. We choose to focus on the RF classifier, but this approach (other the use of TreeInterpreter) could be used with any classifier algorithm. \n",
    "\n",
    "To run this script please first run 'fitting_classifiers.ipynb' to train optimised SVC, LR, RF. This script uses those pre-trained joblib models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protected-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"   \n",
    "DATA = \"CAP\"\n",
    "CLASS_LABEL = 'pca_death_code'  # Target label to predict\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "positive-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "\n",
    "from helper import (pd_print, \n",
    "                    accuracy,\n",
    "                    lemmatize_text,\n",
    "                    summarise_gridsearch_classifier,\n",
    "                    calibrate_random_forest, \n",
    "                    plot_calibration_curve,\n",
    "                    plot_calibration_curve_easy_hard,\n",
    "                    plot_roc_curve,\n",
    "                    compute_all_metrics)\n",
    "\n",
    "from explainability import (get_rf_feature_importances,\n",
    "                            wordcloud,\n",
    "                            run_tree_interpreter,\n",
    "                            get_ti_feature_contributions_for_instance_i,\n",
    "                            get_ti_feature_contributions_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CAP prostate cancer data for preprocessing.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"CAP\":\n",
    "    \n",
    "    from cap_helper import *\n",
    "    \n",
    "    print(\"Loading CAP prostate cancer data for preprocessing.\")\n",
    "    df = load_data(DATA_DIR)\n",
    "    # Combine text from all feature columns into a single string column\n",
    "    df = concatenate_feature_columns(df)\n",
    "    # Link to dates of death:\n",
    "    df = add_dates(df, DATA_DIR)\n",
    "    # Link to reviewer Ids:\n",
    "    df = add_reviewer_ids(df, DATA_DIR)\n",
    "    # Convert all dates to be in units of months before/after death (Note: this regex is not foolproof)\n",
    "    df = convert_dates_relative(df)  \n",
    "    \n",
    "    print(\"Preprocessing complete.\")\n",
    "    \n",
    "    with open('temp_data.pickle', 'wb') as outfile:\n",
    "        pickle.dump(df, outfile)\n",
    "    \n",
    "    \n",
    "## Temporary:\n",
    "else:\n",
    "    with open('temp_data.pickle', 'rb') as infile:\n",
    "        df = pickle.load(infile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "global-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "X,y = df.combined, df[CLASS_LABEL]\n",
    "documents = lemmatize_text(X, stemmer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(documents, \n",
    "                                                    df[CLASS_LABEL], \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unknown-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('models/cap_rf_gridsearch.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "objective-bishop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>contribution</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>bone scan</td>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.026547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>spine</td>\n",
       "      <td>0.025653</td>\n",
       "      <td>0.025653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>widespread</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.023809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>docetaxel</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.022729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>androgen</td>\n",
       "      <td>0.022670</td>\n",
       "      <td>0.022670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>sclerotic</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.021713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>scan</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.020712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>hormone</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.016235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>casodex</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>rib</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.014009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>androgen blockade</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>0.013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>blockade</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.012795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>bony</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.011754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>compression</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.010734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>bone metastasis</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.010695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  contribution  magnitude\n",
       "342           bone scan      0.026547   0.026547\n",
       "1293              spine      0.025653   0.025653\n",
       "1482         widespread      0.023809   0.023809\n",
       "528           docetaxel      0.022729   0.022729\n",
       "264            androgen      0.022670   0.022670\n",
       "1222          sclerotic      0.021713   0.021713\n",
       "1212               scan      0.020712   0.020712\n",
       "681             hormone      0.016235   0.016235\n",
       "375             casodex      0.014661   0.014661\n",
       "1192                rib      0.014009   0.014009\n",
       "265   androgen blockade      0.013143   0.013143\n",
       "331            blockade      0.012795   0.012795\n",
       "343                bony      0.011754   0.011754\n",
       "431         compression      0.010734   0.010734\n",
       "338     bone metastasis      0.010695   0.010695"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fimps = get_rf_feature_importances(clf)\n",
    "assert fimps.feature.is_unique\n",
    "fimps.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
